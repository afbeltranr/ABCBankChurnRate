# Bank Customer Churn Prediction

A production-ready machine learning project to predict customer churn in a banking context, comparing multiple algorithms including **TabM** (Tabular Model), **XGBoost**, **Random Forest**, **Logistic Regression**, **Naive Bayes**, and **AdaBoost**.

## ğŸš€ Quick Start

### Demo Mode (No BigQuery/Kaggle Required)
```bash
git clone <repository-url>
cd ABCBankChurnRate
pip install -r requirements.txt
python demo.py
```

### Production Mode (With Real Data)
```bash
# Set environment variables
export KAGGLE_JSON='{"username":"your_username","key":"your_key"}'
export GCP_SA_KEY='{"type":"service_account",...}'

# Run full pipeline
python main.py --download-new
```

## ğŸ“Š Key Results (Demo)

| Model | F1-Score | ROC-AUC | Training Time |
|-------|----------|---------|---------------|
| **XGBoost** | **0.749** | 0.623 | 0.07s |
| LogisticRegression | 0.748 | 0.661 | 0.004s |
| RandomForest | 0.736 | 0.642 | 0.20s |

## ğŸ—ï¸ Project Structure

```
ABCBankChurnRate/
â”œâ”€â”€ ğŸ“ config/              # Configuration management
â”‚   â””â”€â”€ config.py           # Project settings
â”œâ”€â”€ ğŸ“ notebooks/           # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ ExploratoryDA.ipynb
â”‚   â””â”€â”€ Modelling.ipynb
â”œâ”€â”€ ğŸ“ src/                 # Source code
â”‚   â”œâ”€â”€ ğŸ“ data/           # Data handling
â”‚   â”‚   â”œâ”€â”€ data_loader.py  # Kaggle & BigQuery integration
â”‚   â”‚   â””â”€â”€ preprocessor.py # Feature engineering
â”‚   â”œâ”€â”€ ğŸ“ models/         # ML model implementations
â”‚   â”‚   â”œâ”€â”€ base_model.py   # Abstract base class
â”‚   â”‚   â”œâ”€â”€ logistic_regression.py
â”‚   â”‚   â”œâ”€â”€ naive_bayes.py
â”‚   â”‚   â”œâ”€â”€ random_forest.py
â”‚   â”‚   â”œâ”€â”€ xgboost_model.py
â”‚   â”‚   â”œâ”€â”€ adaboost.py
â”‚   â”‚   â”œâ”€â”€ tabm.py         # TabM implementation
â”‚   â”‚   â””â”€â”€ trainer.py      # Training pipeline
â”‚   â””â”€â”€ ğŸ“ utils/          # Utilities
â”‚       â””â”€â”€ reporting.py    # Stakeholder reports
â”œâ”€â”€ ğŸ“ tests/              # Unit tests
â”œâ”€â”€ demo.py                # Quick demo script
â”œâ”€â”€ main.py                # Production pipeline
â””â”€â”€ requirements.txt       # Dependencies
```

## ğŸ”§ Features

### Data Pipeline
- âœ… **Kaggle Integration**: Automatic dataset download
- âœ… **BigQuery Storage**: Scalable cloud data warehouse
- âœ… **Data Validation**: Comprehensive duplicate and missing value checks
- âœ… **Feature Engineering**: Automated preprocessing pipeline

### Machine Learning
- âœ… **6 ML Algorithms**: Including advanced TabM model
- âœ… **Hyperparameter Tuning**: Grid search with cross-validation
- âœ… **Overfitting Prevention**: Stratified splits and validation
- âœ… **Model Persistence**: Automatic pickle saving/loading

### Production Ready
- âœ… **Comprehensive Testing**: Unit and integration tests
- âœ… **Stakeholder Reports**: Executive summaries and technical reports
- âœ… **Visualization**: Performance comparison plots
- âœ… **Error Handling**: Robust error management
- âœ… **Documentation**: Complete API documentation

## ğŸ“ˆ Model Comparison

### Traditional ML Models
- **Logistic Regression**: Fast, interpretable baseline
- **Naive Bayes**: Probabilistic approach
- **Random Forest**: Ensemble method with feature importance
- **AdaBoost**: Adaptive boosting classifier
- **XGBoost**: Gradient boosting with advanced optimization

### Advanced Models
- **TabM**: Neural network optimized for tabular data
  - Multi-layer perceptron with proper scaling
  - Adaptive learning rates
  - Early stopping to prevent overfitting

## ğŸ¯ Business Impact

### Metrics Explained
- **F1-Score**: Balanced measure of precision and recall
- **ROC-AUC**: Model's ability to distinguish between classes
- **Precision**: % of predicted churners who actually churn
- **Recall**: % of actual churners correctly identified

### Stakeholder Deliverables
1. **Executive Summary** (`demo_results/executive_summary.md`)
2. **Technical Report** (`demo_results/detailed_technical_report.csv`)
3. **Visualization Package** (PNG files for presentations)
4. **Feature Importance Analysis** (Key churn drivers)

## ğŸ§ª Testing

```bash
# Run all tests
python -m pytest tests/ -v

# Run specific test
python -m pytest tests/test_pipeline.py -v

# Run with coverage
python -m pytest tests/ --cov=src
```

## âš™ï¸ Configuration

Edit `config/config.py` to customize:
- Feature engineering strategies
- Model hyperparameters
- Data processing settings
- File paths and BigQuery settings

## ğŸ“‹ Dependencies

Core packages:
- `scikit-learn`: Traditional ML algorithms
- `xgboost`: Gradient boosting
- `pandas`: Data manipulation
- `google-cloud-bigquery`: Cloud data warehouse
- `kaggle`: Data source API

## ğŸ”„ Workflow

### Data Flow
1. **Data Acquisition**: Kaggle â†’ Local â†’ BigQuery
2. **Validation**: Duplicates, missing values, outliers
3. **Preprocessing**: Scaling, encoding, feature engineering
4. **Training**: 6 models with hyperparameter tuning
5. **Evaluation**: Cross-validation and test set metrics
6. **Reporting**: Automated stakeholder deliverables

### Model Training
1. **Data Split**: 60% train, 20% validation, 20% test
2. **Hyperparameter Tuning**: Grid search with 5-fold CV
3. **Model Training**: Best parameters on full training set
4. **Evaluation**: Performance on held-out test set
5. **Persistence**: Save models for future use

## ğŸ Quick Results

After running `python demo.py`, check the `demo_results/` folder for:
- ğŸ“„ Executive summary for business stakeholders
- ğŸ“Š Performance comparison charts
- ğŸ“ˆ Feature importance analysis
- ğŸ“‹ Technical metrics report

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature-name`
3. Run tests: `python -m pytest tests/`
4. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Built with â¤ï¸ for production ML workflows**
